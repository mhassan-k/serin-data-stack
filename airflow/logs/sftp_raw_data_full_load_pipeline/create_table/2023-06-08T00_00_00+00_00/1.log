[2023-06-09 15:07:56,664] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: sftp_raw_data_full_load_pipeline.create_table manual__2023-06-09T15:07:51.635982+00:00 [queued]>
[2023-06-09 15:07:56,682] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: sftp_raw_data_full_load_pipeline.create_table scheduled__2023-06-08T00:00:00+00:00 [queued]>
[2023-06-09 15:07:56,704] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: sftp_raw_data_full_load_pipeline.create_table manual__2023-06-09T15:07:51.635982+00:00 [queued]>
[2023-06-09 15:07:56,705] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2023-06-09 15:07:56,706] {taskinstance.py:1242} INFO - Starting attempt 1 of 1
[2023-06-09 15:07:56,707] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2023-06-09 15:07:56,724] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: sftp_raw_data_full_load_pipeline.create_table scheduled__2023-06-08T00:00:00+00:00 [queued]>
[2023-06-09 15:07:56,725] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2023-06-09 15:07:56,726] {taskinstance.py:1242} INFO - Starting attempt 1 of 1
[2023-06-09 15:07:56,727] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2023-06-09 15:07:56,753] {taskinstance.py:1262} INFO - Executing <Task(PythonOperator): create_table> on 2023-06-09 15:07:51.635982+00:00
[2023-06-09 15:07:56,763] {standard_task_runner.py:52} INFO - Started process 1173 to run task
[2023-06-09 15:07:56,775] {taskinstance.py:1262} INFO - Executing <Task(PythonOperator): create_table> on 2023-06-08 00:00:00+00:00
[2023-06-09 15:07:56,770] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'sftp_raw_data_full_load_pipeline', 'create_table', 'manual__2023-06-09T15:07:51.635982+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/sftp_raw_data_full_load_pipeline.py', '--cfg-path', '/tmp/tmp3tylmtw6', '--error-file', '/tmp/tmptjau6xre']
[2023-06-09 15:07:56,778] {standard_task_runner.py:77} INFO - Job 3: Subtask create_table
[2023-06-09 15:07:56,785] {standard_task_runner.py:52} INFO - Started process 1175 to run task
[2023-06-09 15:07:56,792] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'sftp_raw_data_full_load_pipeline', 'create_table', 'scheduled__2023-06-08T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/sftp_raw_data_full_load_pipeline.py', '--cfg-path', '/tmp/tmpdmjumgh9', '--error-file', '/tmp/tmpkgfrgh5m']
[2023-06-09 15:07:56,801] {standard_task_runner.py:77} INFO - Job 4: Subtask create_table
[2023-06-09 15:07:56,880] {logging_mixin.py:109} INFO - Running <TaskInstance: sftp_raw_data_full_load_pipeline.create_table manual__2023-06-09T15:07:51.635982+00:00 [running]> on host 8cb5811d1998
[2023-06-09 15:07:56,903] {logging_mixin.py:109} INFO - Running <TaskInstance: sftp_raw_data_full_load_pipeline.create_table scheduled__2023-06-08T00:00:00+00:00 [running]> on host 8cb5811d1998
[2023-06-09 15:07:57,016] {taskinstance.py:1414} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=Hassan@gmail.com
AIRFLOW_CTX_DAG_OWNER=Hassan
AIRFLOW_CTX_DAG_ID=sftp_raw_data_full_load_pipeline
AIRFLOW_CTX_TASK_ID=create_table
AIRFLOW_CTX_EXECUTION_DATE=2023-06-09T15:07:51.635982+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-06-09T15:07:51.635982+00:00
[2023-06-09 15:07:57,028] {taskinstance.py:1414} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=Hassan@gmail.com
AIRFLOW_CTX_DAG_OWNER=Hassan
AIRFLOW_CTX_DAG_ID=sftp_raw_data_full_load_pipeline
AIRFLOW_CTX_TASK_ID=create_table
AIRFLOW_CTX_EXECUTION_DATE=2023-06-08T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-06-08T00:00:00+00:00
[2023-06-09 15:07:57,092] {logging_mixin.py:109} INFO - Error creating table (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(leads, 2200) already exists.

[SQL: CREATE TABLE IF NOT EXISTS leads 
(
    "lead_UUID" TEXT NOT NULL,
    "phone_hash" TEXT NOT NULL,
    "email_hash" TEXT DEFAULT NULL,
    "index" INT DEFAULT NULL
);
]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2023-06-09 15:07:57,096] {logging_mixin.py:109} INFO - Successfull
[2023-06-09 15:07:57,097] {python.py:152} INFO - Done. Returned value was: None
[2023-06-09 15:07:57,129] {taskinstance.py:1280} INFO - Marking task as SUCCESS. dag_id=sftp_raw_data_full_load_pipeline, task_id=create_table, execution_date=20230608T000000, start_date=20230609T150756, end_date=20230609T150757
[2023-06-09 15:07:57,144] {local_task_job.py:154} INFO - Task exited with return code 1
[2023-06-09 15:07:57,206] {local_task_job.py:154} INFO - Task exited with return code 0
[2023-06-09 15:07:57,220] {taskinstance.py:1280} INFO - Marking task as FAILED. dag_id=sftp_raw_data_full_load_pipeline, task_id=create_table, execution_date=20230609T150751, start_date=20230609T150756, end_date=20230609T150757
[2023-06-09 15:07:58,689] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-09 15:07:59,153] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-09 15:20:29,613] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: sftp_raw_data_full_load_pipeline.create_table scheduled__2023-06-08T00:00:00+00:00 [queued]>
[2023-06-09 15:20:29,658] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: sftp_raw_data_full_load_pipeline.create_table scheduled__2023-06-08T00:00:00+00:00 [queued]>
[2023-06-09 15:20:29,660] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2023-06-09 15:20:29,661] {taskinstance.py:1242} INFO - Starting attempt 1 of 1
[2023-06-09 15:20:29,662] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2023-06-09 15:20:29,711] {taskinstance.py:1262} INFO - Executing <Task(PythonOperator): create_table> on 2023-06-08 00:00:00+00:00
[2023-06-09 15:20:29,721] {standard_task_runner.py:52} INFO - Started process 2996 to run task
[2023-06-09 15:20:29,728] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'sftp_raw_data_full_load_pipeline', 'create_table', 'scheduled__2023-06-08T00:00:00+00:00', '--job-id', '43', '--raw', '--subdir', 'DAGS_FOLDER/sftp_raw_data_full_load_pipeline.py', '--cfg-path', '/tmp/tmp8loua4b7', '--error-file', '/tmp/tmpppzzgcle']
[2023-06-09 15:20:29,738] {standard_task_runner.py:77} INFO - Job 43: Subtask create_table
[2023-06-09 15:20:29,763] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: sftp_raw_data_full_load_pipeline.create_table manual__2023-06-09T15:20:24.730543+00:00 [queued]>
[2023-06-09 15:20:29,805] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: sftp_raw_data_full_load_pipeline.create_table manual__2023-06-09T15:20:24.730543+00:00 [queued]>
[2023-06-09 15:20:29,806] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2023-06-09 15:20:29,807] {taskinstance.py:1242} INFO - Starting attempt 1 of 1
[2023-06-09 15:20:29,808] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2023-06-09 15:20:29,837] {logging_mixin.py:109} INFO - Running <TaskInstance: sftp_raw_data_full_load_pipeline.create_table scheduled__2023-06-08T00:00:00+00:00 [running]> on host 8cb5811d1998
[2023-06-09 15:20:29,858] {taskinstance.py:1262} INFO - Executing <Task(PythonOperator): create_table> on 2023-06-09 15:20:24.730543+00:00
[2023-06-09 15:20:29,868] {standard_task_runner.py:52} INFO - Started process 2998 to run task
[2023-06-09 15:20:29,875] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'sftp_raw_data_full_load_pipeline', 'create_table', 'manual__2023-06-09T15:20:24.730543+00:00', '--job-id', '44', '--raw', '--subdir', 'DAGS_FOLDER/sftp_raw_data_full_load_pipeline.py', '--cfg-path', '/tmp/tmpcnphyxz2', '--error-file', '/tmp/tmpacua4lff']
[2023-06-09 15:20:29,885] {standard_task_runner.py:77} INFO - Job 44: Subtask create_table
[2023-06-09 15:20:29,958] {taskinstance.py:1414} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=Hassan@gmail.com
AIRFLOW_CTX_DAG_OWNER=Hassan
AIRFLOW_CTX_DAG_ID=sftp_raw_data_full_load_pipeline
AIRFLOW_CTX_TASK_ID=create_table
AIRFLOW_CTX_EXECUTION_DATE=2023-06-08T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-06-08T00:00:00+00:00
[2023-06-09 15:20:29,987] {logging_mixin.py:109} INFO - Running <TaskInstance: sftp_raw_data_full_load_pipeline.create_table manual__2023-06-09T15:20:24.730543+00:00 [running]> on host 8cb5811d1998
[2023-06-09 15:20:30,016] {logging_mixin.py:109} INFO - Error creating table (psycopg2.errors.SyntaxError) syntax error at or near ")"
LINE 17: );
         ^

[SQL: CREATE TABLE IF NOT EXISTS leads_sftp
(
    "ENTRYDATE" TEXT NOT NULL,
    "LEADNUMBER" TEXT NOT NULL,
    "email_hash" TEXT DEFAULT NULL,
    "phone_hash" TEXT DEFAULT NULL,
    "CITY" TEXT DEFAULT NULL,
    "STATE" TEXT DEFAULT NULL,
    "ZIP" TEXT DEFAULT NULL,
    "Appt_Date" TEXT DEFAULT NULL,
    "Set" TEXT DEFAULT NULL,
    "Demo" TEXT DEFAULT NULL,
    "Dispo" TEXT DEFAULT NULL,
    "Job_Status" TEXT DEFAULT NULL,
    "loaded_at" TEXT DEFAULT NULL,

);
]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-06-09 15:20:30,062] {local_task_job.py:154} INFO - Task exited with return code 1
[2023-06-09 15:20:30,108] {taskinstance.py:1414} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=Hassan@gmail.com
AIRFLOW_CTX_DAG_OWNER=Hassan
AIRFLOW_CTX_DAG_ID=sftp_raw_data_full_load_pipeline
AIRFLOW_CTX_TASK_ID=create_table
AIRFLOW_CTX_EXECUTION_DATE=2023-06-09T15:20:24.730543+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-06-09T15:20:24.730543+00:00
[2023-06-09 15:20:30,123] {taskinstance.py:1280} INFO - Marking task as FAILED. dag_id=sftp_raw_data_full_load_pipeline, task_id=create_table, execution_date=20230608T000000, start_date=20230609T152029, end_date=20230609T152030
[2023-06-09 15:20:30,157] {logging_mixin.py:109} INFO - Error creating table (psycopg2.errors.SyntaxError) syntax error at or near ")"
LINE 17: );
         ^

[SQL: CREATE TABLE IF NOT EXISTS leads_sftp
(
    "ENTRYDATE" TEXT NOT NULL,
    "LEADNUMBER" TEXT NOT NULL,
    "email_hash" TEXT DEFAULT NULL,
    "phone_hash" TEXT DEFAULT NULL,
    "CITY" TEXT DEFAULT NULL,
    "STATE" TEXT DEFAULT NULL,
    "ZIP" TEXT DEFAULT NULL,
    "Appt_Date" TEXT DEFAULT NULL,
    "Set" TEXT DEFAULT NULL,
    "Demo" TEXT DEFAULT NULL,
    "Dispo" TEXT DEFAULT NULL,
    "Job_Status" TEXT DEFAULT NULL,
    "loaded_at" TEXT DEFAULT NULL,

);
]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-06-09 15:20:30,208] {local_task_job.py:154} INFO - Task exited with return code 1
[2023-06-09 15:20:30,268] {taskinstance.py:1280} INFO - Marking task as FAILED. dag_id=sftp_raw_data_full_load_pipeline, task_id=create_table, execution_date=20230609T152024, start_date=20230609T152029, end_date=20230609T152030
[2023-06-09 15:20:30,490] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-09 15:20:30,645] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-09 16:51:38,167] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: sftp_raw_data_full_load_pipeline.create_table scheduled__2023-06-08T00:00:00+00:00 [queued]>
[2023-06-09 16:51:38,230] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: sftp_raw_data_full_load_pipeline.create_table scheduled__2023-06-08T00:00:00+00:00 [queued]>
[2023-06-09 16:51:38,231] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2023-06-09 16:51:38,232] {taskinstance.py:1242} INFO - Starting attempt 1 of 1
[2023-06-09 16:51:38,233] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2023-06-09 16:51:38,275] {taskinstance.py:1262} INFO - Executing <Task(PythonOperator): create_table> on 2023-06-08 00:00:00+00:00
[2023-06-09 16:51:38,285] {standard_task_runner.py:52} INFO - Started process 513 to run task
[2023-06-09 16:51:38,295] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'sftp_raw_data_full_load_pipeline', 'create_table', 'scheduled__2023-06-08T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/sftp_raw_data_full_load_pipeline.py', '--cfg-path', '/tmp/tmpvbpcv7c8', '--error-file', '/tmp/tmpkh74ssdk']
[2023-06-09 16:51:38,307] {standard_task_runner.py:77} INFO - Job 3: Subtask create_table
[2023-06-09 16:51:38,422] {logging_mixin.py:109} INFO - Running <TaskInstance: sftp_raw_data_full_load_pipeline.create_table scheduled__2023-06-08T00:00:00+00:00 [running]> on host 6ba608d2de6e
[2023-06-09 16:51:38,565] {taskinstance.py:1414} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=Hassan@gmail.com
AIRFLOW_CTX_DAG_OWNER=Hassan
AIRFLOW_CTX_DAG_ID=sftp_raw_data_full_load_pipeline
AIRFLOW_CTX_TASK_ID=create_table
AIRFLOW_CTX_EXECUTION_DATE=2023-06-08T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-06-08T00:00:00+00:00
[2023-06-09 16:51:38,629] {logging_mixin.py:109} INFO - Successfull
[2023-06-09 16:51:38,630] {python.py:152} INFO - Done. Returned value was: None
[2023-06-09 16:51:38,676] {taskinstance.py:1280} INFO - Marking task as SUCCESS. dag_id=sftp_raw_data_full_load_pipeline, task_id=create_table, execution_date=20230608T000000, start_date=20230609T165138, end_date=20230609T165138
[2023-06-09 16:51:38,749] {local_task_job.py:154} INFO - Task exited with return code 0
[2023-06-09 16:51:39,239] {local_task_job.py:264} INFO - 22 downstream tasks scheduled from follow-on schedule check
